{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a935e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame prima dello scaling:\n",
      "   Feature1  Feature2  Feature3\n",
      "0       100       0.1      1000\n",
      "1       200       0.5       800\n",
      "2       300       0.2      1200\n",
      "3       400       0.8      1500\n",
      "\n",
      "DataFrame dopo lo scaling:\n",
      "   Feature1  Feature2  Feature3\n",
      "0  0.000000  0.000000  0.285714\n",
      "1  0.333333  0.571429  0.000000\n",
      "2  0.666667  0.142857  0.571429\n",
      "3  1.000000  1.000000  1.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "# Creiamo un DataFrame di esempio\n",
    "data = {'Feature1': [100, 200, 300, 400],\n",
    "        'Feature2': [0.1, 0.5, 0.2, 0.8],\n",
    "        'Feature3': [1000, 800, 1200, 1500]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Visualizziamo il DataFrame prima dello scaling\n",
    "print(\"DataFrame prima dello scaling:\")\n",
    "print(df)\n",
    "\n",
    "# Iniziamo con il Min-Max scaling\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(df)\n",
    "\n",
    "# Creiamo un nuovo DataFrame con le features scalate\n",
    "scaled_df = pd.DataFrame(scaled_data, columns=df.columns)\n",
    "\n",
    "# Visualizziamo il DataFrame dopo lo scaling\n",
    "print(\"\\nDataFrame dopo lo scaling:\")\n",
    "print(scaled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e08bb1bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame prima dello scaling:\n",
      "   Feature1  Feature2  Feature3\n",
      "0       100       0.1      1000\n",
      "1       200       0.5       800\n",
      "2       300       0.2      1200\n",
      "3       400       0.8      1500\n",
      "\n",
      "DataFrame dopo Min-Max scaling:\n",
      "   Feature1  Feature2  Feature3\n",
      "0  0.000000  0.000000  0.285714\n",
      "1  0.333333  0.571429  0.000000\n",
      "2  0.666667  0.142857  0.571429\n",
      "3  1.000000  1.000000  1.000000\n",
      "\n",
      "DataFrame dopo Z-score scaling:\n",
      "   Feature1  Feature2  Feature3\n",
      "0 -1.341641 -1.095445 -0.483368\n",
      "1 -0.447214  0.365148 -1.256757\n",
      "2  0.447214 -0.730297  0.290021\n",
      "3  1.341641  1.460593  1.450105\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "# Creiamo un DataFrame di esempio\n",
    "data = {'Feature1': [100, 200, 300, 400],\n",
    "        'Feature2': [0.1, 0.5, 0.2, 0.8],\n",
    "        'Feature3': [1000, 800, 1200, 1500]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Visualizziamo il DataFrame prima dello scaling\n",
    "print(\"DataFrame prima dello scaling:\")\n",
    "print(df)\n",
    "\n",
    "# Min-Max scaling\n",
    "min_max_scaler = MinMaxScaler()\n",
    "min_max_scaled_data = min_max_scaler.fit_transform(df)\n",
    "min_max_scaled_df = pd.DataFrame(min_max_scaled_data, columns=df.columns)\n",
    "\n",
    "# Z-score scaling\n",
    "standard_scaler = StandardScaler()\n",
    "standard_scaled_data = standard_scaler.fit_transform(df)\n",
    "standard_scaled_df = pd.DataFrame(standard_scaled_data, columns=df.columns)\n",
    "\n",
    "# Visualizziamo i DataFrame dopo lo scaling\n",
    "print(\"\\nDataFrame dopo Min-Max scaling:\")\n",
    "print(min_max_scaled_df)\n",
    "\n",
    "print(\"\\nDataFrame dopo Z-score scaling:\")\n",
    "print(standard_scaled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3a3be80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame prima dello scaling:\n",
      "   Feature1  Feature2  Feature3\n",
      "0       100       0.1      1000\n",
      "1       200       0.5       800\n",
      "2       300       0.2      1200\n",
      "3       400       0.8      1500\n",
      "\n",
      "DataFrame dopo Min-Max scaling:\n",
      "   Feature1  Feature2  Feature3\n",
      "0  0.000000  0.000000  0.285714\n",
      "1  0.333333  0.571429  0.000000\n",
      "2  0.666667  0.142857  0.571429\n",
      "3  1.000000  1.000000  1.000000\n",
      "\n",
      "DataFrame dopo Z-score scaling:\n",
      "   Feature1  Feature2  Feature3\n",
      "0 -1.341641 -1.095445 -0.483368\n",
      "1 -0.447214  0.365148 -1.256757\n",
      "2  0.447214 -0.730297  0.290021\n",
      "3  1.341641  1.460593  1.450105\n",
      "\n",
      "DataFrame dopo Robust scaling:\n",
      "   Feature1  Feature2  Feature3\n",
      "0 -1.000000    -0.625 -0.307692\n",
      "1 -0.333333     0.375 -0.923077\n",
      "2  0.333333    -0.375  0.307692\n",
      "3  1.000000     1.125  1.230769\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "\n",
    "# Creiamo un DataFrame di esempio\n",
    "data = {'Feature1': [100, 200, 300, 400],\n",
    "        'Feature2': [0.1, 0.5, 0.2, 0.8],\n",
    "        'Feature3': [1000, 800, 1200, 1500]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Visualizziamo il DataFrame prima dello scaling\n",
    "print(\"DataFrame prima dello scaling:\")\n",
    "print(df)\n",
    "\n",
    "# Min-Max scaling\n",
    "min_max_scaler = MinMaxScaler()\n",
    "min_max_scaled_data = min_max_scaler.fit_transform(df)\n",
    "min_max_scaled_df = pd.DataFrame(min_max_scaled_data, columns=df.columns)\n",
    "\n",
    "# Z-score scaling\n",
    "standard_scaler = StandardScaler()\n",
    "standard_scaled_data = standard_scaler.fit_transform(df)\n",
    "standard_scaled_df = pd.DataFrame(standard_scaled_data, columns=df.columns)\n",
    "\n",
    "# Robust scaling\n",
    "robust_scaler = RobustScaler()\n",
    "robust_scaled_data = robust_scaler.fit_transform(df)\n",
    "robust_scaled_df = pd.DataFrame(robust_scaled_data, columns=df.columns)\n",
    "\n",
    "# Visualizziamo i DataFrame dopo lo scaling\n",
    "print(\"\\nDataFrame dopo Min-Max scaling:\")\n",
    "print(min_max_scaled_df)\n",
    "\n",
    "print(\"\\nDataFrame dopo Z-score scaling:\")\n",
    "print(standard_scaled_df)\n",
    "\n",
    "print(\"\\nDataFrame dopo Robust scaling:\")\n",
    "print(robust_scaled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9855ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Colore_Blu  Colore_Rosso  Colore_Verde\n",
      "0           0             1             0\n",
      "1           1             0             0\n",
      "2           0             0             1\n",
      "3           0             1             0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Creiamo un DataFrame di esempio con una variabile categorica\n",
    "data = {'Colore': ['Rosso', 'Blu', 'Verde', 'Rosso']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Applichiamo l'encoding One-Hot\n",
    "df_encoded = pd.get_dummies(df, columns=['Colore'])\n",
    "\n",
    "# Visualizziamo il DataFrame dopo l'encoding\n",
    "print(df_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e3b5b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Livello_Istruzione  Livello_Istruzione_Ordinale\n",
      "0  Scuola elementare                            1\n",
      "1       Scuola media                            2\n",
      "2            Diploma                            3\n",
      "3  Scuola elementare                            1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Creiamo un DataFrame di esempio con una variabile categorica ordinale\n",
    "data = {'Livello_Istruzione': ['Scuola elementare', 'Scuola media', 'Diploma', 'Scuola elementare']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Definiamo l'ordine delle categorie\n",
    "livelli_istruzione_ordine = {'Scuola elementare': 1, 'Scuola media': 2, 'Diploma': 3}\n",
    "\n",
    "# Applichiamo l'encoding ordinale\n",
    "df['Livello_Istruzione_Ordinale'] = df['Livello_Istruzione'].map(livelli_istruzione_ordine)\n",
    "\n",
    "# Visualizziamo il DataFrame dopo l'encoding\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f78ac9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
